type: plm
name: bert_lstm_crf
delimiter: "\t"
input: "resources/data/dataset/ner/zh/ccks/address/0621"
file_format: bies
output: "resources/data/output/ner/zh/ccks/address/0621/bert_lstm_crf/"
summary: "resources/data/output/ner/zh/ccks/address/0621/bert_lstm_crf/summary"
max_length: 60
model_path: resources/data/pretrained/bert-base-chinese
per_device_train_batch_size: 16
per_device_eval_batch_size: 8
plm_lr: 2.095e-5
not_plm_lr: 0.00937
weight_decay: 0.0
model_type: bert
decode_type: general
num_train_epochs: 9
gradient_accumulation_steps: 1
lr_scheduler_type: linear
num_warmup_steps: 0
seed: 100
do_lower_case: True
task_name: ner
cpu: False

# plm:2.095e-5 not:0.00937,num:9,val:0.9234